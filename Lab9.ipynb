{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Algorithms Lab CIA 2\n",
    "\n",
    "- Rohit Arrunachalam IOT B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.Implement a neural network from scratch. Take any dataset. If you take a regression problem, use the equations derived in the class. If you take a classification problem, use the below equations: (run minimum 200 iterations and get the result). Use the gradient descent optimization technique for weight optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-23T17:15:57.925687Z",
     "iopub.status.busy": "2023-07-23T17:15:57.925071Z",
     "iopub.status.idle": "2023-07-23T17:16:02.477848Z",
     "shell.execute_reply": "2023-07-23T17:16:02.476413Z",
     "shell.execute_reply.started": "2023-07-23T17:15:57.925574Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "d = pd.read_csv(r\"C:\\Users\\Rohit\\SNU\\Sem 6\\ML\\cia2\\dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T17:16:05.561482Z",
     "iopub.status.busy": "2023-07-23T17:16:05.560889Z",
     "iopub.status.idle": "2023-07-23T17:16:05.605450Z",
     "shell.execute_reply": "2023-07-23T17:16:05.603850Z",
     "shell.execute_reply.started": "2023-07-23T17:16:05.561432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T17:16:08.212125Z",
     "iopub.status.busy": "2023-07-23T17:16:08.211692Z",
     "iopub.status.idle": "2023-07-23T17:16:08.349886Z",
     "shell.execute_reply": "2023-07-23T17:16:08.348480Z",
     "shell.execute_reply.started": "2023-07-23T17:16:08.212089Z"
    }
   },
   "outputs": [],
   "source": [
    "d = np.array(d)\n",
    "m,n = d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-23T17:16:10.414819Z",
     "iopub.status.busy": "2023-07-23T17:16:10.414335Z",
     "iopub.status.idle": "2023-07-23T17:16:10.556411Z",
     "shell.execute_reply": "2023-07-23T17:16:10.554963Z",
     "shell.execute_reply.started": "2023-07-23T17:16:10.414780Z"
    }
   },
   "outputs": [],
   "source": [
    "dd = d.T\n",
    "y = dd[0]\n",
    "x = dd[1:n]\n",
    "x = x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T13:22:31.866767Z",
     "iopub.status.busy": "2023-03-21T13:22:31.865508Z",
     "iopub.status.idle": "2023-03-21T13:22:31.880139Z",
     "shell.execute_reply": "2023-03-21T13:22:31.878924Z",
     "shell.execute_reply.started": "2023-03-21T13:22:31.866717Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate():\n",
    "    w1 = 0.1*np.random.randn(100,783)\n",
    "    b1 = 0.1*np.random.randn(100,1)\n",
    "    w2 = 0.1*np.random.randn(10,100)\n",
    "    b2 = 0.1*np.random.randn(10,1)\n",
    "    return w1,b1,w2,b2\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def forward(w1,b1,w2,b2,x):\n",
    "    z1 = w1.dot(x)+b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = w2.dot(a1)+b2\n",
    "    a2 = sigmoid(z2)\n",
    "    return z1,a1,z2,a2\n",
    "\n",
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def der(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "    \n",
    "def back(z1,a1,z2,a2,w1,w2,x,y):\n",
    "    one_y = one_hot(y)\n",
    "    er = a2 - one_y\n",
    "    delt = er * der(z2)\n",
    "    dw2 = 1 / m *delt.dot(a1.T)\n",
    "    db2 = 1 / m * np.sum(er)\n",
    "    delt_hid = w2.T.dot(delt) * der(z1)\n",
    "    dw1 = 1 / m * delt_hid.dot(x.T)\n",
    "    db1 = 1 / m * np.sum(delt_hid)\n",
    "    \n",
    "    return dw1,db1,dw2,db2\n",
    "\n",
    "def update(w1,b1,w2,b2,dw1,db1,dw2,db2,a):\n",
    "    w1 = w1 - a*dw1\n",
    "    b1 = b1 - a *db1\n",
    "    w2 = w2 - a*dw2\n",
    "    b2 = b2 - a *db2\n",
    "    return w1,b1,w2,b2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T13:22:33.477071Z",
     "iopub.status.busy": "2023-03-21T13:22:33.476627Z",
     "iopub.status.idle": "2023-03-21T13:22:33.486387Z",
     "shell.execute_reply": "2023-03-21T13:22:33.485134Z",
     "shell.execute_reply.started": "2023-03-21T13:22:33.477029Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(a2):\n",
    "    return np.argmax(a2, 0)\n",
    "\n",
    "def get_accuracy(predictions, y):\n",
    "    print(predictions, y)\n",
    "    return np.sum(predictions == y) / y.size\n",
    "\n",
    "def gradient(x,y,a,it):\n",
    "    w1,b1,w2,b2 = generate()\n",
    "    for i in range(it):\n",
    "        z1,a1,z2,a2 = forward(w1,b1,w2,b2,x)\n",
    "        dw1,db1,dw2,db2 = back(z1,a1,z2,a2,w1,w2,x,y)\n",
    "        w1,b1,w2,b2 = update(w1,b1,w2,b2,dw1,db1,dw2,db2,a)\n",
    "        if i % 10 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(a2)\n",
    "            print(get_accuracy(predictions, y))\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T13:22:34.355267Z",
     "iopub.status.busy": "2023-03-21T13:22:34.354831Z",
     "iopub.status.idle": "2023-03-21T13:23:42.042627Z",
     "shell.execute_reply": "2023-03-21T13:23:42.040609Z",
     "shell.execute_reply.started": "2023-03-21T13:22:34.355229Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[8 0 8 ... 0 8 8] [0 0 0 ... 0 0 0]\n",
      "0.13202380952380952\n",
      "Iteration:  10\n",
      "[8 0 8 ... 0 3 4] [0 0 0 ... 0 0 0]\n",
      "0.15328571428571428\n",
      "Iteration:  20\n",
      "[8 0 9 ... 0 3 4] [0 0 0 ... 0 0 0]\n",
      "0.14833333333333334\n",
      "Iteration:  30\n",
      "[8 7 9 ... 0 3 4] [0 0 0 ... 0 0 0]\n",
      "0.145\n",
      "Iteration:  40\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.1433809523809524\n",
      "Iteration:  50\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.1423095238095238\n",
      "Iteration:  60\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.14152380952380952\n",
      "Iteration:  70\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.14114285714285715\n",
      "Iteration:  80\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.14083333333333334\n",
      "Iteration:  90\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.1405\n",
      "Iteration:  100\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.14026190476190475\n",
      "Iteration:  110\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.13995238095238094\n",
      "Iteration:  120\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.13976190476190475\n",
      "Iteration:  130\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.1395952380952381\n",
      "Iteration:  140\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.13957142857142857\n",
      "Iteration:  150\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.1395952380952381\n",
      "Iteration:  160\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.13947619047619048\n",
      "Iteration:  170\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.13935714285714285\n",
      "Iteration:  180\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.13911904761904761\n",
      "Iteration:  190\n",
      "[8 7 9 ... 0 7 4] [0 0 0 ... 0 0 0]\n",
      "0.13904761904761906\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = gradient(x, y, 0.10,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. For the same dataset, build a neural network using keras library. Run the same number of epochs and compare the results obtained with your model vs the built-in keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28, 1)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "750/750 [==============================] - 5s 5ms/step - loss: 0.0511 - accuracy: 0.9845 - val_loss: 0.0949 - val_accuracy: 0.9726\n",
      "Epoch 2/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0402 - accuracy: 0.9883 - val_loss: 0.0903 - val_accuracy: 0.9734\n",
      "Epoch 3/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0319 - accuracy: 0.9914 - val_loss: 0.0910 - val_accuracy: 0.9737\n",
      "Epoch 4/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0259 - accuracy: 0.9927 - val_loss: 0.0901 - val_accuracy: 0.9763\n",
      "Epoch 5/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0207 - accuracy: 0.9943 - val_loss: 0.0891 - val_accuracy: 0.9760\n",
      "Epoch 6/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 0.0894 - val_accuracy: 0.9767\n",
      "Epoch 7/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 0.0890 - val_accuracy: 0.9762\n",
      "Epoch 8/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0116 - accuracy: 0.9974 - val_loss: 0.1000 - val_accuracy: 0.9741\n",
      "Epoch 9/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.1027 - val_accuracy: 0.9753\n",
      "Epoch 10/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0961 - val_accuracy: 0.9762\n",
      "Epoch 11/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.1024 - val_accuracy: 0.9747\n",
      "Epoch 12/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0054 - accuracy: 0.9990 - val_loss: 0.0985 - val_accuracy: 0.9772\n",
      "Epoch 13/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.1054 - val_accuracy: 0.9762\n",
      "Epoch 14/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0984 - val_accuracy: 0.9778\n",
      "Epoch 15/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.1018 - val_accuracy: 0.9776\n",
      "Epoch 16/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.1039 - val_accuracy: 0.9776\n",
      "Epoch 17/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.1080 - val_accuracy: 0.9768\n",
      "Epoch 18/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.1072 - val_accuracy: 0.9772\n",
      "Epoch 19/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.1142 - val_accuracy: 0.9776\n",
      "Epoch 20/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.1133 - val_accuracy: 0.9783\n",
      "Epoch 21/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1236 - val_accuracy: 0.9764\n",
      "Epoch 22/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.1519 - val_accuracy: 0.9732\n",
      "Epoch 23/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.1275 - val_accuracy: 0.9758\n",
      "Epoch 24/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0046 - accuracy: 0.9986 - val_loss: 0.1231 - val_accuracy: 0.9765\n",
      "Epoch 25/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.1170 - val_accuracy: 0.9779\n",
      "Epoch 26/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 6.9505e-04 - accuracy: 0.9999 - val_loss: 0.1176 - val_accuracy: 0.9790\n",
      "Epoch 27/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.1377 - val_accuracy: 0.9741\n",
      "Epoch 28/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.1219 - val_accuracy: 0.9784\n",
      "Epoch 29/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.9579e-04 - accuracy: 0.9999 - val_loss: 0.1217 - val_accuracy: 0.9772\n",
      "Epoch 30/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.8459e-04 - accuracy: 0.9999 - val_loss: 0.1193 - val_accuracy: 0.9796\n",
      "Epoch 31/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.1617 - val_accuracy: 0.9718\n",
      "Epoch 32/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.1370 - val_accuracy: 0.9763\n",
      "Epoch 33/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 8.0632e-04 - accuracy: 0.9999 - val_loss: 0.1219 - val_accuracy: 0.9785\n",
      "Epoch 34/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.5030e-04 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9788\n",
      "Epoch 35/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4832e-04 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9792\n",
      "Epoch 36/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1808e-04 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9795\n",
      "Epoch 37/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0113e-04 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9793\n",
      "Epoch 38/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.2052 - val_accuracy: 0.9674\n",
      "Epoch 39/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1399 - val_accuracy: 0.9763\n",
      "Epoch 40/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 8.7377e-04 - accuracy: 0.9998 - val_loss: 0.1309 - val_accuracy: 0.9783\n",
      "Epoch 41/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8778e-04 - accuracy: 1.0000 - val_loss: 0.1309 - val_accuracy: 0.9783\n",
      "Epoch 42/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6250e-04 - accuracy: 1.0000 - val_loss: 0.1298 - val_accuracy: 0.9796\n",
      "Epoch 43/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 9.3176e-05 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9790\n",
      "Epoch 44/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.4522e-05 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9796\n",
      "Epoch 45/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.2132e-05 - accuracy: 1.0000 - val_loss: 0.1341 - val_accuracy: 0.9795\n",
      "Epoch 46/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.2443e-05 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 0.9795\n",
      "Epoch 47/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.1694e-05 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9800\n",
      "Epoch 48/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0121 - accuracy: 0.9964 - val_loss: 0.1530 - val_accuracy: 0.9768\n",
      "Epoch 49/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.0001e-04 - accuracy: 0.9999 - val_loss: 0.1364 - val_accuracy: 0.9785\n",
      "Epoch 50/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6850e-04 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9798\n",
      "Epoch 51/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 8.0603e-05 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9792\n",
      "Epoch 52/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.2155e-05 - accuracy: 1.0000 - val_loss: 0.1380 - val_accuracy: 0.9796\n",
      "Epoch 53/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.1361e-05 - accuracy: 1.0000 - val_loss: 0.1392 - val_accuracy: 0.9800\n",
      "Epoch 54/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.3289e-05 - accuracy: 1.0000 - val_loss: 0.1413 - val_accuracy: 0.9795\n",
      "Epoch 55/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.7225e-05 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9799\n",
      "Epoch 56/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.0873e-05 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9805\n",
      "Epoch 57/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.6306e-05 - accuracy: 1.0000 - val_loss: 0.1444 - val_accuracy: 0.9797\n",
      "Epoch 58/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.2571 - val_accuracy: 0.9633\n",
      "Epoch 59/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.1701 - val_accuracy: 0.9766\n",
      "Epoch 60/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.4048e-04 - accuracy: 0.9999 - val_loss: 0.1577 - val_accuracy: 0.9781\n",
      "Epoch 61/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 5.4321e-04 - accuracy: 0.9999 - val_loss: 0.1544 - val_accuracy: 0.9783\n",
      "Epoch 62/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 7.3013e-05 - accuracy: 1.0000 - val_loss: 0.1507 - val_accuracy: 0.9793\n",
      "Epoch 63/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.1503e-05 - accuracy: 1.0000 - val_loss: 0.1511 - val_accuracy: 0.9792\n",
      "Epoch 64/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.3558e-05 - accuracy: 1.0000 - val_loss: 0.1515 - val_accuracy: 0.9791\n",
      "Epoch 65/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.7856e-05 - accuracy: 1.0000 - val_loss: 0.1523 - val_accuracy: 0.9796\n",
      "Epoch 66/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.3303e-05 - accuracy: 1.0000 - val_loss: 0.1529 - val_accuracy: 0.9796\n",
      "Epoch 67/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9765e-05 - accuracy: 1.0000 - val_loss: 0.1543 - val_accuracy: 0.9795\n",
      "Epoch 68/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 3.1252e-05 - accuracy: 1.0000 - val_loss: 0.2177 - val_accuracy: 0.9733\n",
      "Epoch 69/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0120 - accuracy: 0.9964 - val_loss: 0.1665 - val_accuracy: 0.9770\n",
      "Epoch 70/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1683 - val_accuracy: 0.9774\n",
      "Epoch 71/200\n",
      "750/750 [==============================] - 3s 5ms/step - loss: 2.2708e-04 - accuracy: 1.0000 - val_loss: 0.1547 - val_accuracy: 0.9793\n",
      "Epoch 72/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.3402e-05 - accuracy: 1.0000 - val_loss: 0.1550 - val_accuracy: 0.9802\n",
      "Epoch 73/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.7674e-05 - accuracy: 1.0000 - val_loss: 0.1554 - val_accuracy: 0.9802\n",
      "Epoch 74/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.0256e-05 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9800\n",
      "Epoch 75/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.4903e-05 - accuracy: 1.0000 - val_loss: 0.1562 - val_accuracy: 0.9803\n",
      "Epoch 76/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0872e-05 - accuracy: 1.0000 - val_loss: 0.1565 - val_accuracy: 0.9803\n",
      "Epoch 77/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7467e-05 - accuracy: 1.0000 - val_loss: 0.1569 - val_accuracy: 0.9804\n",
      "Epoch 78/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4515e-05 - accuracy: 1.0000 - val_loss: 0.1571 - val_accuracy: 0.9807\n",
      "Epoch 79/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1942e-05 - accuracy: 1.0000 - val_loss: 0.1585 - val_accuracy: 0.9803\n",
      "Epoch 80/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0196e-05 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 0.9807\n",
      "Epoch 81/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 9.0716e-06 - accuracy: 1.0000 - val_loss: 0.1604 - val_accuracy: 0.9807\n",
      "Epoch 82/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.0766e-06 - accuracy: 1.0000 - val_loss: 0.1605 - val_accuracy: 0.9806\n",
      "Epoch 83/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.2003e-06 - accuracy: 1.0000 - val_loss: 0.1636 - val_accuracy: 0.9802\n",
      "Epoch 84/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0119 - accuracy: 0.9969 - val_loss: 0.1830 - val_accuracy: 0.9784\n",
      "Epoch 85/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1702 - val_accuracy: 0.9798\n",
      "Epoch 86/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6927e-04 - accuracy: 1.0000 - val_loss: 0.1705 - val_accuracy: 0.9793\n",
      "Epoch 87/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.4325e-05 - accuracy: 1.0000 - val_loss: 0.1700 - val_accuracy: 0.9797\n",
      "Epoch 88/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.3986e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9800\n",
      "Epoch 89/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9029e-05 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9797\n",
      "Epoch 90/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5678e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9798\n",
      "Epoch 91/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3047e-05 - accuracy: 1.0000 - val_loss: 0.1688 - val_accuracy: 0.9800\n",
      "Epoch 92/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0851e-05 - accuracy: 1.0000 - val_loss: 0.1695 - val_accuracy: 0.9794\n",
      "Epoch 93/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 8.9762e-06 - accuracy: 1.0000 - val_loss: 0.1693 - val_accuracy: 0.9797\n",
      "Epoch 94/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.4893e-06 - accuracy: 1.0000 - val_loss: 0.1701 - val_accuracy: 0.9802\n",
      "Epoch 95/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.2732e-06 - accuracy: 1.0000 - val_loss: 0.1692 - val_accuracy: 0.9803\n",
      "Epoch 96/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.0771e-06 - accuracy: 1.0000 - val_loss: 0.1698 - val_accuracy: 0.9800\n",
      "Epoch 97/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.3635e-06 - accuracy: 1.0000 - val_loss: 0.1708 - val_accuracy: 0.9804\n",
      "Epoch 98/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.4593e-06 - accuracy: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9799\n",
      "Epoch 99/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.2076 - val_accuracy: 0.9758\n",
      "Epoch 100/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1893 - val_accuracy: 0.9768\n",
      "Epoch 101/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.1817 - val_accuracy: 0.9787\n",
      "Epoch 102/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5924e-04 - accuracy: 1.0000 - val_loss: 0.1769 - val_accuracy: 0.9790\n",
      "Epoch 103/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.1522e-05 - accuracy: 1.0000 - val_loss: 0.1780 - val_accuracy: 0.9794\n",
      "Epoch 104/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6398e-05 - accuracy: 1.0000 - val_loss: 0.1777 - val_accuracy: 0.9794\n",
      "Epoch 105/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3263e-05 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9795\n",
      "Epoch 106/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0976e-05 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9796\n",
      "Epoch 107/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 9.1025e-06 - accuracy: 1.0000 - val_loss: 0.1771 - val_accuracy: 0.9796\n",
      "Epoch 108/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.6363e-06 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9799\n",
      "Epoch 109/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.4213e-06 - accuracy: 1.0000 - val_loss: 0.1773 - val_accuracy: 0.9794\n",
      "Epoch 110/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.3366e-06 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9797\n",
      "Epoch 111/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.5006e-06 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9799\n",
      "Epoch 112/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.7156e-06 - accuracy: 1.0000 - val_loss: 0.1788 - val_accuracy: 0.9799\n",
      "Epoch 113/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.0346e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9796\n",
      "Epoch 114/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.5739e-06 - accuracy: 1.0000 - val_loss: 0.1792 - val_accuracy: 0.9801\n",
      "Epoch 115/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.1102e-06 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9799\n",
      "Epoch 116/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.1841 - val_accuracy: 0.9762\n",
      "Epoch 117/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 0.1833 - val_accuracy: 0.9784\n",
      "Epoch 118/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.5702e-04 - accuracy: 0.9998 - val_loss: 0.1772 - val_accuracy: 0.9797\n",
      "Epoch 119/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.9123e-05 - accuracy: 1.0000 - val_loss: 0.1740 - val_accuracy: 0.9804\n",
      "Epoch 120/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8840e-05 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9804\n",
      "Epoch 121/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4099e-05 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9808\n",
      "Epoch 122/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1370e-05 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9806\n",
      "Epoch 123/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 9.2486e-06 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 0.9808\n",
      "Epoch 124/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.5859e-06 - accuracy: 1.0000 - val_loss: 0.1731 - val_accuracy: 0.9810\n",
      "Epoch 125/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.2262e-06 - accuracy: 1.0000 - val_loss: 0.1735 - val_accuracy: 0.9808\n",
      "Epoch 126/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.0888e-06 - accuracy: 1.0000 - val_loss: 0.1742 - val_accuracy: 0.9810\n",
      "Epoch 127/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.1658e-06 - accuracy: 1.0000 - val_loss: 0.1743 - val_accuracy: 0.9812\n",
      "Epoch 128/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.3585e-06 - accuracy: 1.0000 - val_loss: 0.1755 - val_accuracy: 0.9811\n",
      "Epoch 129/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.7413e-06 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 0.9812\n",
      "Epoch 130/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2210e-06 - accuracy: 1.0000 - val_loss: 0.1768 - val_accuracy: 0.9811\n",
      "Epoch 131/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8183e-06 - accuracy: 1.0000 - val_loss: 0.1778 - val_accuracy: 0.9807\n",
      "Epoch 132/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4653e-06 - accuracy: 1.0000 - val_loss: 0.1791 - val_accuracy: 0.9806\n",
      "Epoch 133/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1812e-06 - accuracy: 1.0000 - val_loss: 0.1824 - val_accuracy: 0.9801\n",
      "Epoch 134/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 9.6634e-07 - accuracy: 1.0000 - val_loss: 0.1821 - val_accuracy: 0.9804\n",
      "Epoch 135/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0064 - accuracy: 0.9986 - val_loss: 0.2714 - val_accuracy: 0.9706\n",
      "Epoch 136/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.2111 - val_accuracy: 0.9777\n",
      "Epoch 137/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.6161e-04 - accuracy: 0.9999 - val_loss: 0.1943 - val_accuracy: 0.9788\n",
      "Epoch 138/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.0952e-04 - accuracy: 1.0000 - val_loss: 0.1903 - val_accuracy: 0.9796\n",
      "Epoch 139/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6595e-05 - accuracy: 1.0000 - val_loss: 0.1885 - val_accuracy: 0.9795\n",
      "Epoch 140/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 9.5759e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9797\n",
      "Epoch 141/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.2291e-06 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9798\n",
      "Epoch 142/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.8724e-06 - accuracy: 1.0000 - val_loss: 0.1881 - val_accuracy: 0.9797\n",
      "Epoch 143/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.7401e-06 - accuracy: 1.0000 - val_loss: 0.1878 - val_accuracy: 0.9799\n",
      "Epoch 144/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.9572e-06 - accuracy: 1.0000 - val_loss: 0.1882 - val_accuracy: 0.9797\n",
      "Epoch 145/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.2611e-06 - accuracy: 1.0000 - val_loss: 0.1883 - val_accuracy: 0.9801\n",
      "Epoch 146/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.6724e-06 - accuracy: 1.0000 - val_loss: 0.1880 - val_accuracy: 0.9802\n",
      "Epoch 147/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2203e-06 - accuracy: 1.0000 - val_loss: 0.1888 - val_accuracy: 0.9802\n",
      "Epoch 148/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8104e-06 - accuracy: 1.0000 - val_loss: 0.1890 - val_accuracy: 0.9799\n",
      "Epoch 149/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5034e-06 - accuracy: 1.0000 - val_loss: 0.1898 - val_accuracy: 0.9799\n",
      "Epoch 150/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2086e-06 - accuracy: 1.0000 - val_loss: 0.1893 - val_accuracy: 0.9800\n",
      "Epoch 151/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0024e-06 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9801\n",
      "Epoch 152/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 8.2077e-07 - accuracy: 1.0000 - val_loss: 0.1909 - val_accuracy: 0.9803\n",
      "Epoch 153/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.6842e-07 - accuracy: 1.0000 - val_loss: 0.1936 - val_accuracy: 0.9804\n",
      "Epoch 154/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.6211e-07 - accuracy: 1.0000 - val_loss: 0.1952 - val_accuracy: 0.9803\n",
      "Epoch 155/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.5643e-07 - accuracy: 1.0000 - val_loss: 0.1957 - val_accuracy: 0.9803\n",
      "Epoch 156/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.2392 - val_accuracy: 0.9758\n",
      "Epoch 157/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.2072 - val_accuracy: 0.9783\n",
      "Epoch 158/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.2354e-04 - accuracy: 0.9998 - val_loss: 0.2097 - val_accuracy: 0.9775\n",
      "Epoch 159/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2460 - val_accuracy: 0.9769\n",
      "Epoch 160/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.2198 - val_accuracy: 0.9772\n",
      "Epoch 161/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.2168 - val_accuracy: 0.9781\n",
      "Epoch 162/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.2197 - val_accuracy: 0.9771\n",
      "Epoch 163/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.2239 - val_accuracy: 0.9777\n",
      "Epoch 164/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.3688e-04 - accuracy: 0.9999 - val_loss: 0.2033 - val_accuracy: 0.9797\n",
      "Epoch 165/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9936e-05 - accuracy: 1.0000 - val_loss: 0.2015 - val_accuracy: 0.9798\n",
      "Epoch 166/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 8.5784e-06 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9795\n",
      "Epoch 167/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.0253e-06 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9794\n",
      "Epoch 168/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.7009e-06 - accuracy: 1.0000 - val_loss: 0.2017 - val_accuracy: 0.9794\n",
      "Epoch 169/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.6971e-06 - accuracy: 1.0000 - val_loss: 0.2018 - val_accuracy: 0.9793\n",
      "Epoch 170/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.9417e-06 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9790\n",
      "Epoch 171/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.3519e-06 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9794\n",
      "Epoch 172/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.8790e-06 - accuracy: 1.0000 - val_loss: 0.2019 - val_accuracy: 0.9796\n",
      "Epoch 173/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4894e-06 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9797\n",
      "Epoch 174/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2006e-06 - accuracy: 1.0000 - val_loss: 0.2031 - val_accuracy: 0.9797\n",
      "Epoch 175/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 9.6424e-07 - accuracy: 1.0000 - val_loss: 0.2033 - val_accuracy: 0.9802\n",
      "Epoch 176/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.7213e-07 - accuracy: 1.0000 - val_loss: 0.2037 - val_accuracy: 0.9800\n",
      "Epoch 177/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.1401e-07 - accuracy: 1.0000 - val_loss: 0.2051 - val_accuracy: 0.9800\n",
      "Epoch 178/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.1321e-07 - accuracy: 1.0000 - val_loss: 0.2052 - val_accuracy: 0.9799\n",
      "Epoch 179/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.0982e-07 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 0.9796\n",
      "Epoch 180/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.3041e-07 - accuracy: 1.0000 - val_loss: 0.2075 - val_accuracy: 0.9799\n",
      "Epoch 181/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.6895e-07 - accuracy: 1.0000 - val_loss: 0.2080 - val_accuracy: 0.9798\n",
      "Epoch 182/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2191e-07 - accuracy: 1.0000 - val_loss: 0.2094 - val_accuracy: 0.9800\n",
      "Epoch 183/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.7733e-07 - accuracy: 1.0000 - val_loss: 0.2105 - val_accuracy: 0.9804\n",
      "Epoch 184/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.4625e-07 - accuracy: 1.0000 - val_loss: 0.2117 - val_accuracy: 0.9801\n",
      "Epoch 185/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2225e-07 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9798\n",
      "Epoch 186/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.0068e-07 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 0.9796\n",
      "Epoch 187/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 7.7056e-08 - accuracy: 1.0000 - val_loss: 0.2140 - val_accuracy: 0.9799\n",
      "Epoch 188/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 6.3007e-08 - accuracy: 1.0000 - val_loss: 0.2165 - val_accuracy: 0.9803\n",
      "Epoch 189/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 5.1598e-08 - accuracy: 1.0000 - val_loss: 0.2178 - val_accuracy: 0.9799\n",
      "Epoch 190/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 4.4083e-08 - accuracy: 1.0000 - val_loss: 0.2196 - val_accuracy: 0.9798\n",
      "Epoch 191/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.5224e-08 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 0.9801\n",
      "Epoch 192/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 3.0202e-08 - accuracy: 1.0000 - val_loss: 0.2219 - val_accuracy: 0.9807\n",
      "Epoch 193/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.5605e-08 - accuracy: 1.0000 - val_loss: 0.2227 - val_accuracy: 0.9805\n",
      "Epoch 194/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 2.2098e-08 - accuracy: 1.0000 - val_loss: 0.2234 - val_accuracy: 0.9805\n",
      "Epoch 195/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.9304e-08 - accuracy: 1.0000 - val_loss: 0.2248 - val_accuracy: 0.9805\n",
      "Epoch 196/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.6898e-08 - accuracy: 1.0000 - val_loss: 0.2271 - val_accuracy: 0.9803\n",
      "Epoch 197/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.5261e-08 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 0.9803\n",
      "Epoch 198/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.3875e-08 - accuracy: 1.0000 - val_loss: 0.2272 - val_accuracy: 0.9807\n",
      "Epoch 199/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.2564e-08 - accuracy: 1.0000 - val_loss: 0.2287 - val_accuracy: 0.9806\n",
      "Epoch 200/200\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 1.1491e-08 - accuracy: 1.0000 - val_loss: 0.2291 - val_accuracy: 0.9808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21326718250>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1987 - accuracy: 0.9818\n",
      "Accuracy on test set: 0.9818000197410583\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Accuracy on test set:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly say that The Keras model achieved better accuracy on the same task than the gradient descent one built from  scratch due to lesser loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7363,
     "sourceId": 10507,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30301,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
